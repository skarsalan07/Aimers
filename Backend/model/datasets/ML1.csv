question,answer
What is supervised learning?,"""Supervised learning is a machine learning approach where the model is trained on labeled data. Each input is paired with the correct output, enabling the model to learn the mapping and make accurate predictions on new, unseen inputs."""
What is unsupervised learning?,"""Unsupervised learning deals with data that has no labels. The goal is to explore the structure of the data, like grouping similar data points through clustering or reducing dimensionality using algorithms such as PCA."""
What is reinforcement learning?,"""Reinforcement learning is a type of learning where an agent interacts with an environment, learns from feedback in the form of rewards or penalties, and aims to maximize cumulative rewards over time."""
What is a feature in machine learning?,"""A feature is an individual measurable property or characteristic of the data used as input to the model. Good features significantly influence the performance of machine learning algorithms."""
What is a label in machine learning?,"""A label is the output variable that the model is trained to predict. It is only available in supervised learning and helps guide the learning process."""
What is the training set?,"""The training set is the portion of the dataset used to train a machine learning model. It contains input features and corresponding labels (in supervised learning)."""
What is the test set?,"""The test set is used to evaluate how well the trained model performs on unseen data. It helps determine the model's generalization ability."""
What is cross‑validation?,"""Cross-validation is a model evaluation technique where the dataset is split into multiple parts. The model is trained on some parts and validated on others, helping reduce overfitting and assess performance."""
What is accuracy?,"""Accuracy is the ratio of correctly predicted instances to the total number of predictions. It's a simple metric but can be misleading for imbalanced datasets."""
What is precision?,"""Precision is the proportion of true positive predictions among all positive predictions made by the model. It indicates how many of the predicted positives are actually correct."""
What is recall?,"""Recall is the ratio of true positive predictions to all actual positive cases in the dataset. It shows the model’s ability to capture all relevant cases."""
What is F1‑score?,"""F1-score is the harmonic mean of precision and recall, providing a single metric that balances both concerns, especially useful in imbalanced datasets."""
What is a confusion matrix?,"""A confusion matrix is a table that describes the performance of a classification model. It shows true positives, false positives, true negatives, and false negatives."""
What is a decision tree?,"""A decision tree is a supervised learning algorithm that splits data into branches based on feature conditions until a decision or prediction is made at the leaf nodes."""
What is a random forest?,"""A random forest is an ensemble learning method that builds multiple decision trees and merges their outputs to improve accuracy and reduce overfitting."""
What is a neural network?,"""A neural network is a computational model inspired by the human brain. It consists of layers of interconnected nodes that transform inputs through learned weights to generate outputs."""
What is deep learning?,"""Deep learning is a branch of machine learning that uses neural networks with multiple layers (deep architectures) to model complex patterns in data."""
What is a perceptron?,"""A perceptron is a basic neural network unit used for binary classification. It calculates a weighted sum of inputs and applies an activation function to make decisions."""
What is gradient descent?,"""Gradient descent is an optimization algorithm that minimizes the loss function by updating model parameters in the direction that reduces the error using computed gradients."""
What is the learning rate?,"""The learning rate controls how much model weights are updated during training. A high rate may overshoot minima, while a low rate may slow convergence."""
What is a loss function?,"""A loss function quantifies how far the predicted output is from the actual output. The goal of training is to minimize this loss."""
What is mean squared error?,"""Mean squared error (MSE) is the average of squared differences between predicted and actual values, used commonly in regression problems."""
What is cross‑entropy loss?,"""Cross-entropy loss is used in classification problems and measures the difference between two probability distributions: the predicted and the actual."""
What is regularization?,"""Regularization is a technique used to reduce overfitting by penalizing large weights in the model, thus simplifying the learned function."""
What is L1 regularization?,"""L1 regularization adds the absolute value of weights to the loss function. It can result in sparse models by driving some weights to zero."""
What is L2 regularization?,"""L2 regularization adds the squared value of weights to the loss function, preventing large weight values and improving generalization."""
What is dropout?,"""Dropout is a regularization technique where randomly selected neurons are ignored during training to prevent overfitting and improve model robustness."""
What is batch normalization?,"""Batch normalization normalizes the inputs of each layer to maintain stable distributions, speeding up training and improving model performance."""
What is a convolutional neural network (CNN)?,"""CNNs are deep learning models specialized for processing grid-like data such as images, using convolution layers to extract spatial hierarchies."""
What is a recurrent neural network (RNN)?,"""RNNs are neural networks designed for sequential data. They maintain memory of previous inputs via hidden states to capture temporal dependencies."""
What is a long short‑term memory (LSTM)?,"""LSTMs are a type of RNN designed to remember long-term dependencies using gates to control the flow of information and prevent vanishing gradients."""
What is overfitting in machine learning?,"""Overfitting occurs when a model learns the noise in training data and performs poorly on unseen data. It captures specific patterns that don't generalize."""
What is underfitting?,"""Underfitting happens when a model is too simple to capture the underlying pattern of the data, leading to poor performance on both training and test sets."""
What is bias in machine learning?,"""Bias is the error introduced by approximating a real-world problem with a simplified model. High bias can cause underfitting."""
What is variance in machine learning?,"""Variance is the model's sensitivity to fluctuations in the training data. High variance can lead to overfitting and poor generalization."""
What is the bias‑variance trade‑off?,"""The bias-variance trade-off describes the balance between the error introduced by bias and variance. A good model finds the optimal balance."""
What is feature scaling?,"""Feature scaling transforms features to a common scale, improving convergence of gradient-based models and reducing the dominance of features with large ranges."""
What is normalization?,"""Normalization scales input features to a specific range, typically [0,1], making algorithms like k-NN and gradient descent work effectively."""
What is standardization?,"""Standardization transforms features to have zero mean and unit variance. It's especially useful when features follow a Gaussian distribution."""
What is one‑hot encoding?,"""One-hot encoding converts categorical variables into binary vectors, enabling algorithms to process categorical data numerically."""
What is label encoding?,"""Label encoding assigns each unique category a number. It’s simple but can imply an ordinal relationship where none exists."""
What is feature engineering?,"""Feature engineering involves creating new input features or transforming existing ones to improve model performance and accuracy."""
What is principal component analysis (PCA)?,"""PCA is a technique for reducing dimensionality by transforming features into orthogonal components that capture maximum variance."""
What is k‑means clustering?,"""K-means clustering partitions data into k groups by minimizing intra-cluster variance, commonly used in unsupervised learning tasks."""
What is hierarchical clustering?,"""Hierarchical clustering builds a tree of clusters using a bottom-up (agglomerative) or top-down (divisive) approach to group similar data."""
What is DBSCAN?,"""DBSCAN is a density-based clustering algorithm that groups together points that are closely packed and identifies noise as outliers."""
What is the elbow method?,"""The elbow method helps determine the optimal number of clusters in k-means by plotting explained variance and finding the 'elbow' point."""
What is the ROC curve?,"""The ROC curve plots true positive rate vs. false positive rate for different thresholds, helping assess classifier performance."""
What is AUC?,"""AUC (Area Under the ROC Curve) quantifies the overall ability of a classifier to distinguish between classes. Higher AUC indicates better performance."""
What is the precision–recall curve?,"""This curve plots precision against recall at various thresholds and is useful for evaluating classifiers, especially on imbalanced datasets."""
What is hyperparameter tuning?,"""Hyperparameter tuning involves finding the best set of parameters (like learning rate, depth) that control model training but are not learned from data."""
What is grid search?,"""Grid search is a brute-force method to find the best hyperparameters by exhaustively trying all combinations within a predefined grid."""
What is random search?,"""Random search randomly selects combinations of hyperparameters and evaluates them, often more efficient than grid search for large spaces."""
What is Bayesian optimization?,"""Bayesian optimization models the performance of hyperparameters using probabilistic functions to guide the search toward better configurations."""
What is early stopping?,"""Early stopping halts training when performance on validation data stops improving, helping to prevent overfitting."""
What is the bias–variance trade‑off?,"""The bias-variance trade-off describes the balance between the error introduced by bias and variance. A good model finds the optimal balance."""
